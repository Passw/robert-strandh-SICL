\chapter{Compiler}
\label{chap-compiler}

\section{General description}

\section{Different uses of the compiler}

The compiler is used in several different situations.  There are
different use cases, so it is appropriate to distinguish these cases
and identify their respective roles.

\begin{itemize}
\item File compilation.  This use case is relevant when
  \texttt{compile-file} is invoked.  It takes a \commonlisp{} source
  file and generates a so-called \emph{fasl} file.  Since \sysname{}
  \emph{fasl} files are merely textual versions of the abstract syntax
  tree produced by the \iconoclast{} library as described in
  \refChap{chap-compiled-files}, only that phase is involved in file
  compilation.

\item AST compilation.  This use case is relevant when there is an
  existing abstract syntax tree that must be converted into a
  \emph{code object} as described in
  \refSec{data-representation-code-objects}.  The code object is
  initially independent of any particular global environment.  The act
  of associating the code object with any particular environment is
  called \emph{tying} it.  This process, as well as the difference
  between an untied and a tied code object is described in
  \refChap{chap-tying-a-code-object}.

\item \emph{Lambda-expression} compilation.  This use case is relevant
  when \texttt{compile} is called with arguments \texttt{nil} and a
  \emph{lambda expression}, and by \texttt{coerce} to convert a lambda
  expression to a function.  It compiles the lambda expression in the
  \emph{null lexical environment}, and it produces a \emph{function
    object}.  This use case can be seen as the creation of an abstract
  syntax tree from the lambda expression, followed by AST compilation.

\item \emph{Top-level expression} compilation.  This use case is
  relevant when \texttt{eval} is invoked.  It produces a function with
  no parameters which is then immediately \emph{called} by
  \texttt{eval}.  This use case can be thought of as wrapping the
  top-level expression in a lambda expression and then applying
  lambda-expression compilation to it.

\end{itemize}

In addition to these use cases, we also distinguish between different
compilers along an orthogonal dimension:

\begin{itemize}
\item An \emph{intrinsic} (or \emph{native}) compiler is a compiler
  that produces code for its host \commonlisp{} system.
\item An \emph{extrinsic} compiler is a compiler that produces code
  for a \commonlisp{} system other than its host system.  An extrinsic
  compiler is also known as a \emph{cross compiler}.
\end{itemize}

Specific issues related to cross compilation are discussed in
\refChap{chap-cross-compilation}.

\section{Compilation phases}

\subsection{Reading the source code}

\sysname{} uses the \eclector{}%
\footnote{https://github.com/s-expressionists/Eclector}
implementation-independent version of the standard function
\texttt{read} and related functions.

While \eclector{} is also the default reader of \sysname{}, for use
with the compiler, \eclector{} is used to produce a \emph{concrete
  syntax tree}%
\footnote{https://github.com/s-expressionists/Concrete-Syntax-Tree} or
CST for short.  A CST is a direct mirror of the representation of the
source code as ordinary S-expressions, except that each sub-expression
is wrapped in a standard object that may contain other information
\emph{about} the expression.  In particular, the \sysname{} compiler
includes information about \emph{source location} in the CST, so that
this information can be propagated throughout the compilation
procedure.

In order to accomplish source tracking, \sysname{} starts by reading
the entire source file into memory.  The internal representation of
the source code is a vector of lines, where each line is a string.  We
use this representation, rather than a single string for the entire
file, in order to avoid the issue of how newlines are represented.

The macro \texttt{with-source-tracking-stream-from-file} in the
package named \texttt{sicl-source-tracking} takes a file
specification and turns it into a Gray stream by reading the entire
file contents and then wrapping that contents in an instance of the
standard class \texttt{source-tracking-stream}.  An instance of that
class contains the vector of lines of the initial file, the index of the
\emph{current line}, and the index of the \emph{current character}
within the current line.

The library \texttt{trivial-gray-streams} is used to define methods on
the generic functions \texttt{stream-read-char} and
\texttt{stream-unread-char}.  These methods modify the index of the
current line and the current character as appropriate.

The system \texttt{sicl-source-tracking} also defines methods on two
generic functions provided by the \eclector{} subsystem
\texttt{eclector.parse-result}.  The method on
\texttt{source-position} returns an instance of the class
\texttt{sicl-source-position}.  Instances of this class contain the
entire file contents as the vector of lines, together with the line
and character index taken from the current values of the stream.  The
method on \texttt{make-source-range} simply constructs a \texttt{cons}
of the start and the end position, provided they are both non-null.

As a result of this source tracking, every CST that corresponds to a
precise location in the source file has a start and an end position
associated with it.  Not every CST has a location in the source file,
however.  For example, if the source file contains a list in the form
of an opening parenthesis followed by several elements separated by
spaces, then only the CSTs corresponding to the entire list, and those
associated with each element, have source positions associated with
them.  CSTs corresponding to the \texttt{cons} cells of the list,
other than the first, do not have source positions associated with
them.

The source is read in a loop that reads top-level expressions until
end of file.  The expressions are then wrapped in a CST representing
the special operator \texttt{progn} so as to produce a single CST for
the entire source code in the file.

\subsection{Conversion from CST to AST}

Once the CST has been produced by \eclector{}, it is converted to an
\emph{abstract syntax tree}, or AST for short.  We are using the AST
classed defined by the Iconoclast%
\footnote{https://github.com/robert-strandh/Iconoclast}
library.  The conversion itself is done by the Common boot%
\footnote{https://github.com/robert-strandh/Common-boot}
library.  This conversion involves the use of a \emph{global
  environment} as defined in
\refSec{sec-first-class-global-environments} and of lexical
environments that evolve during the compilation procedure, as describe
in \refSec{sec-lexical-compile-time-environments}.

In the AST, all macro calls have been expanded, and all other aspects
of the compilation environment have been taken into account.  For that
reason, the AST is independent of the compilation environment.

The AST has a textual representation, so the AST can be saved to a
file and a \emph{similar} AST can be created by an application of the
\texttt{read} function (using a particular read table) to the contents
of the file.  In fact, this textual representation is the \emph{fasl}
format that \sysname{} uses.  It fulfills the requirements for
\emph{minimal compilation} defined by the \commonlisp{} standard.
For more information, see \refChap{chap-compiled-files}.

\subsection{Conversion from AST to HIR}

The acronym HIR stands for \emph{High-level Intermediate
  Representation}.  This representation is defined by \cleavir{} and
documented in chapter 6 of the \cleavir{} documentation.
The main characteristic of HIR is that the objects manipulated are all
\commonlisp{} objects, though some of them might be \emph{unboxed}.

\subsection{HIR transformations}

\subsubsection{Introducing explicit argument processing}

When HIR code is created by \cleavir{} the outputs of an
\texttt{enter-instruction} consist of lexical variables that should be
initialized according to the lambda list stored in that instruction.
This process is deliberately hidden in the initial HIR version,
because it is highly dependent on the implementation.

In \sysname{}, we handle the situation by introducing two new
instructions, namely: \texttt{compute-argument-count-instruction} and
\texttt{argument-instruction}.  The HIR code that parses the arguments
according to the lambda list is sufficiently complex that we
documented it separately, in \refChap{chap-processing-arguments}.

\subsubsection{Handling \texttt{named-call-instruction}s and similar}

It used to be the case that the AST-to-HIR phase generated
\texttt{fdefinition-instruction}s, but it no longer does.  Instead,
for function calls with a name in the operator position, it now
generates \texttt{named-call-instruction}s.  These instructions
(together with other instructions that will ultimately turn into calls
to known functions; see below) are scanned for in the HIR code, and a
list of \emph{call-sites} is established.  Otherwise, these
instructions are not processed at all.  In the final native code, they
will turn into unconditional jumps, and the target address will be
filled in by the call-site manager when the code is tied to an
environment.

Other instructions are treated the same way.  In particular
\texttt{catch-instruction}s, \texttt{bind-instruction}s,
\texttt{unwind-instruction}s, \texttt{symbol-value-instruction}s,
\texttt{set-symbol-value-instruction}s.  When these instructions are
scanned for in HIR code, the call sites that are established reflect
the exact kind of instruction.

\subsubsection{Eliminating \texttt{fixed-to-multiple-instruction}s}

Recall that the \texttt{fixed-to-multiple-instruction} takes a
number of inputs and stores the corresponding values as multiple
values in the distinguished location for this purpose.

Eliminating a \texttt{fixed-to-multiple-instruction} involves the
introduction of two new instruction classes.

The first one is named \texttt{initialize-return-values-instruction}.
It takes a single constant input value which is a fixnum that
indicates the number of multiple values that the distinguished
location should hold.

The second one is named \texttt{set-return-value-instruction}.  It
takes two inputs.  The first input is a constant input containing a
fixnum that indicates the index (starting at 0) of the value to
store.  The second input is the value to store at that index.

We generate a single \texttt{initialize-return-values-instruction}
which is given the length of the input list to the original
instruction.  Then we generate as many
\texttt{set-return-value-instruction}s as there are inputs, each one
given the next input in the list of inputs of the original
instruction.

Notice that if the \texttt{fixed-to-multiple-instruction} has no
inputs, we still generate an
\texttt{initialize-return-values-instruction} with the value 0, and a
single \texttt{set-return-value-instruction} with the value
\texttt{nil} in its constant input.

\subsubsection{Eliminating \texttt{multiple-to-fixed-instruction}s}

Recall that the \texttt{multiple-to-fixed-instruction} fetches
multiple values from the distinguished location for this purpose, and
stores each one in a fixed lexical location.

Eliminating the \texttt{multiple-to-fixed-instruction} involves the
introduction of two new instruction classes.

The first one is name
\texttt{compute-return-value-count-instruction}.  It has no inputs and
a single output that will contain the number of values in the
distinguished location.

The second one is named \texttt{return-value-instruction}.  It has a
single input which is the index of the value in the distinguished
location that is wanted.  It has a single output which is a lexical
location that will contain the value at the given index in the
distinguished location.

This transformation is more complicated than the one used for
eliminating the \texttt{fixed-to-multiple-instruction}, because of the
default values that are given to outputs with an index greater than or
equal to the number of available values.  The generated code contains
two main branches, each one with as many stages as there are outputs
of the original instruction.  In one branch, the index of the desired
value is less than the number of available values, so the
corresponding value is assigned to the output.  In the other branch,
the index of the desired value is greater than or equal to the number
of available values, so \texttt{nil} is assigned to the output
instead.  At each stage in the first branch, a test is emitted to see
whether there are any more values.  If that is not the case, control
is transferred to the second branch.

As a special optimization, when there is a single output of the
original instruction, we do not emit any
\texttt{compute-return-value-count-instruction}.  Instead a single
\texttt{return-value-instruction} is generated with an index of $0$.
We are allowed to do that because even when no values are returned
from a function, the first location must contain \texttt{nil}.

\subsubsection{Handling non-trivial constants}

Non-trivial constant inputs are handled by the introduction of a
\texttt{load-constant-instruction}.  This instruction has no inputs
and a single lexical output.  The instruction itself contains the
constant.  During later phases, this instruction is replaced by a
PC-relative load instruction that fetches the constant from a vector
of constants allocated separately.

\subsubsection{Eliminating \texttt{create-cell-instruction}s}

A \texttt{create-cell-instruction} is turned into a
\texttt{funcall-instruction} with \texttt{cons} as the function to
call and \texttt{nil} as both the arguments.

The \texttt{cons} function is loaded from the static environment.  To
do that, we emit an \texttt{aref-instruction} with the static
environment location and the offset of the \texttt{cons} function in
the static environment.

Similarly, the constant \texttt{nil} is loaded from the static
environment.  Again, we emit an \texttt{aref-instruction}, this time with
an index corresponding to the position of \texttt{nil} in the
static environment.%
\fixme{Investigate whether we could annotate the
  \texttt{create-cell-instruction}s with inputs representing the
  \texttt{cons} function as output from an
  \texttt{fdefinition-instruction} and the constant \texttt{nil}.  It
  may not be possible since a \texttt{create-cell} instruction is
  created as a result of closure conversion, and adding an
  \texttt{fdefinition-instruction} means that it must be hoisted, and
  followed by closure conversion.  Perhaps it is possible if we do the
  closure conversion inside-out, since there are no
  \texttt{create-cell-instruction}s in the innermost function.}

\subsubsection{Eliminating \texttt{fetch-instruction}s}

A \texttt{fetch-instruction} is turned into an
\texttt{aref-instruction} with a modified index input, in that we add
$4$ to the constant input of the \texttt{fetch-instruction} in order
to get the constant input to the \texttt{aref-instruction}.  The
reason for this difference is that the \texttt{fetch-instruction} does
not take into account the four initial elements of the static
environment.

\subsubsection{Eliminating \texttt{read-cell-instruction}s}

A \texttt{read-cell-instruction} is simply replaced by a
\texttt{car-instruction}.  The \texttt{car-instruction} assumes that
its argument is a \texttt{cons} cell, but we know that is the case,
because we created the cell by a call to the \texttt{cons} function.

\subsubsection{Eliminating \texttt{write-cell-instruction}s}

A \texttt{write-cell-instruction} is simply replaced by a
\texttt{rplaca-instruction}.  The \texttt{rplaca-instruction} assumes
that its argument is a \texttt{cons} cell, but we know that is the
case, because we created the cell by a call to the \texttt{cons}
function.

\subsection{Conversion from HIR to MIR}

MIR differs from HIR in that address calculations are explicit.

The conversion from HIR to MIR starts by \emph{expanding}
\texttt{funcall-instruction}s as described below.  This transformation
is done first, because it introduces \texttt{read-nook-instruction}s
that must be expanded by transformations that are made later.

Following the expansion of \texttt{funcall-instruction}s, conversion
to MIR is done one function (i.e. starting with an
\texttt{enter-instruction} at a time.  For each function, conversion
starts by eliminating \texttt{enclose-instruction}s in that function.
Following that, the function \texttt{process-instruction} is called
for each instruction in the function.

\subsubsection{Expanding \texttt{funcall-instruction}s}

In HIR, the \texttt{funcall-instruction} takes a function object as
its first input.  During the conversion to MIR, we replace that input
with three inputs:

\begin{enumerate}
\item A lexical location containing a fixnum that represents the
  absolute address of the code of the callee.
\item A lexical location containing the static environment to be
  passed to the callee.
\item A lexical location containing the dynamic environment to be
  passed to the callee.
\end{enumerate}

The first two items are fetched from the rack of the function object.
We use a \texttt{nook-read} instruction for each one.  For this
reason, \texttt{funcall-instruction}s must be expanded before
\texttt{nook-read-instruction}s and \texttt{nook-write-instruction}s.

The dynamic environment is a lexical location that is kept in a slot
of the \texttt{funcall-instruction}.

\subsubsection{Eliminating \texttt{enclose-instruction}s}

The \texttt{enclose-instruction} is turned into a
\texttt{funcall-instruction}.  The function being called is an element
of the static environment (currently at index 1).

The arguments to the \texttt{enclose} function are:

\begin{enumerate}
\item A constant representing the absolute address of the entry point
  of the function resulting from the enclose operation.
\item An arbitrary number of inputs that become the elements of the
  static environment of the function resulting from the enclose
  operation.
\end{enumerate}

The absolute address of the entry point is not known when this
transformation is applied.  We therefore generate a constant of 0
instead.  But we must keep track of this constant so that it can be
patched, once the address of the entry point is known.  For that
reason, we do not generate an ordinary constant input, but an instance
of a subclass of \texttt{constant-input} named
\texttt{entry-point-input} that, in addition to the constant value,
also contains a reference to the enter instruction being enclosed.

The remaining arguments to the \texttt{funcall-instruction} are just
the inputs of the \texttt{enclose-instruction} being replaced.

Therefore, the complete sequence of instructions that replaces the
\texttt{enclose-instruction} is:

\begin{enumerate}
\item An \texttt{aref-instruction} taking as inputs the lexical
  location holding the static environment and a constant input holding
  the value 1.  The output is a lexical location holding the
  \texttt{enclose} function to be called.
\item A \texttt{funcall-instruction} with a first input being the
  lexical location of the output of the \texttt{aref-instruction} and
  the remaining inputs being the inputs of the
  \texttt{enclose-intruction}.
\item A \texttt{return-value-instruction} with a constant input having
  the value $0$, meaning we obtain the first and only value returned
  by the preceding \texttt{funcall} instruction.
\end{enumerate}

\subsubsection{Eliminating \texttt{car-instruction}s}

To eliminate a \texttt{car-instruction} we first insert an
\texttt{unsigned-sub-instruction}.  There are two inputs to that
instruction.  The first input is the input of the original
instruction.  The second input is an \texttt{immediate-input} with a
value of 1.  The output is a \texttt{raw-integer}.  This instruction
has a single successor, meaning that we do not care about any carry,
since there can not be any.

Next, we change the class of the \texttt{car-instruction} so that it
becomes a \texttt{memref1\-instruction}.  The input of the
\texttt{memref1-instruction} is the \texttt{raw-integer} computed by
the \texttt{unsigned-sub-instruction}.  The output is the output of
the original \texttt{car-instruction}.

\subsubsection{Eliminating \texttt{cdr-instruction}s}

To eliminate a \texttt{cdr-instruction} we first insert an
\texttt{unsigned-add-instruction}.  There are two inputs to that
instruction.  The first input is the input of the original
instruction.  The second input is an \texttt{immediate-input} with a
value of 7.  The output is a \texttt{raw-integer}.  This instruction
has a single successor, meaning that we do not care about any carry,
since there can not be any.

Next, we change the class of the \texttt{cdr-instruction} so that it
becomes a \texttt{memref1\-instruction}.  The input of the
\texttt{memref1-instruction} is the \texttt{raw-integer} computed by
the \texttt{unsigned-sub-instruction}.  The output is the output of
the original \texttt{cdr-instruction}.

\subsubsection{Eliminating \texttt{rplaca-instruction}s}

To eliminate an \texttt{rplaca-instruction} we first insert an
\texttt{unsigned-sub-instruction}.  There are two inputs to that
instruction.  The first input is the first input of the original
instruction.  The second input is an \texttt{immediate-input} with a
value of 1.  The output is a \texttt{raw-integer}.  This instruction
has a single successor, meaning that we do not care about any carry,
since there can not be any.

Next, we change the class of the \texttt{rplaca-instruction} so that
it becomes a \texttt{memset1-instruction}.  The \texttt{:address}
input of the \texttt{memset1-instruction} is the \texttt{raw-integer}
computed by the \texttt{unsigned-sub-instruction}.  The
\texttt{:value} input of the \texttt{memset1-instruction} is the
second input of the original instruction.

\subsubsection{Eliminating \texttt{rplacd-instruction}s}

To eliminate an \texttt{rplacd-instruction} we first insert an
\texttt{unsigned-add-instruction}.  There are two inputs to that
instruction.  The first input is the first input of the original
instruction.  The second input is an \texttt{immediate-input} with a
value of 7.  The output is a \texttt{raw-integer}.  This instruction
has a single successor, meaning that we do not care about any carry,
since there can not be any.

Next, we change the class of the \texttt{rplacd-instruction} so that
it becomes a \texttt{memset1-instruction}.  The \texttt{:address}
input of the \texttt{memset1-instruction} is the \texttt{raw-integer}
computed by the \texttt{unsigned-sub-instruction}.  The
\texttt{:value} input of the \texttt{memset1-instruction} is the
second input of the original instruction.

\subsubsection{Eliminating \texttt{aref-instruction}s}

To eliminate an \texttt{aref-instruction}, we first insert an
\texttt{unsigned-add-instruction}.  There are two inputs to that
instruction.  The first input is the first input of the original
instruction.  The second input is an \texttt{immediate-input} with a
value of 3.  The output is a \texttt{raw-integer}.  This instruction
has a single successor, meaning that we do not care about any carry,
since there can not be any.

Next, we insert a \texttt{memref1-instruction}.  The input to this
instruction is the \texttt{raw-integer} computed in the first step.
The output is a fresh lexical location that will hold the \emph{rack}
of the array.

The next step depends on whether the array is a bit-array or not,
because if it is a bit-array we can't just use a memory reference to
read the element; it has to be masked and shifted from a bigger
datum.

\subsection{Conversion from MIR to LIR}

\subsubsection{Register allocation}

Assume that for each program point we maintain a set of
\emph{entries}.  Each entry corresponds to a lexical variable that is
\emph{live} at that program point.  An entry contains the following
information:

\begin{itemize}
\item The live variable itself.
\item A bitmap representing occupied stack locations.
\item An estimated \emph{distance} until it is going to be needed (in
  a register) next.
\item A set of locations where it is currently available.  This set is
  represented as a list.  An element of the set can be a specific
  register, or a specific stack location.  This set has at least one
  element in it.
\end{itemize}

There are two aspects to this technique.  The first aspect is the
computation of the estimated distance.  The second aspect is how
decisions are made to assign a lexical variable to a register and
which variable to no longer assign to a register when there are not
enough registers to go around.

We first consider the second problem, and discuss the first problem later.

Now let us assume that we have some register assignment A before
executing some instruction I.  We want to process this instruction and
determine a register assignment B after the execution if I.
Processing the instruction may involve altering it, but also perhaps
inserting new instructions before it and after it.

Let us assume that we have a MIR instruction of the form $c \leftarrow
a\thinspace op\thinspace b$, where $c$ is a lexical variable, and $a$,
and $b$ are either lexical variables or immediate inputs.  We further
assume that at least one of $a$ and $b$ is not an immediate input.
Our task is to generate one or more x86-style LIR instructions of the
form $x \leftarrow x\thinspace op\thinspace y$, where $x$ is a
register, and $y$ is either a register, an immediate input, or a stack
location.

\setlistdepth{20}

\newlist{legal}{enumerate}{20}
%\setlist[legal]{label*=\arabic*.}
\setlist[legal,1]{label=\arabic*.}
\setlist[legal,2]{label=\alph*.}
\setlist[legal,3]{label=\roman*.}
\setlist[legal,4]{label=\Alph*.}
\setlist[legal,5]{label=\Roman*.}
\setlist[legal,6]{label=\arabic*.}
\setlist[legal,7]{label=\alph*.}
\setlist[legal,8]{label=\roman*.}
\setlist[legal,9]{label=\Alph*.}
\renewlist{legal}{enumerate}{20}

First, the following steps are executed in order:

\begin{legal}
\item If $a$ is an immediate input, and $I$ is commutative, then $a$
  and $b$ are swapped.
\item If either:
  \begin{legal}
  \item $b$ is an immediate input,
  \item $b$ is already assigned to a register, or
    \begin{legal}
    \item $b$ is assigned only to a stack location,
    \item $I$ permits a memory location as its second operand, and
    \item either $b$ is dead after $I$ or the next use of $b$ is far
      in the future,
    \end{legal}
  \end{legal}
  then no further processing is done for $b$.
\item Otherwise, a new register, say $s$ is allocated for $b$ as a
  second operand.  An instruction is inserted that loads $b$ into $s$.
\item If either:
  \begin{legal}
  \item $a$ is an immediate input,
  \item $a$ is assigned only to a stack location and the next use of
    $a$ is far in the future, or
  \item $a$ is assigned only to a stack location and $a = c$,
  \end{legal}
  then a new register, say $r$, is allocated for $c$.  An instruction
  is inserted before $I$ that assigns $a$ to $r$.
\item Otherwise, $a$ and $b$ are both assigned to some registers say
  $r$ and $s$, respectively.  Then the instructions for that case are
  followed, as described below.
\end{legal}

Following are the instructions used when $a$ and $b$ are both assigned
to registers, say $r$ and $s$ respectively:

\begin{legal}
\item Either $a$, $b$ and $c$ are all distinct, or $a = b$, but $c$ is
  different.
  \begin{legal}
  \item $a$ is dead after $I$.  Then make $c$ be assigned to $r$
    after $I$.
  \item $a$ is live after $I$.
    \begin{legal}
    \item $a$ is needed soon after $I$.
      \begin{legal}
      \item $c$ is needed soon after $I$. Allocate a new register, say
        $t$, and assign it to $c$.  Insert an instruction before $I$
        that copies $r$ to $t$.
      \item $c$ is not needed soon after $I$.  Allocate a new
        register, say $t$, and assign it to $c$.  Insert an
        instruction before $I$ that copies $r$ to $t$.
      \end{legal}
    \item $a$ is not needed soon after $I$.
      \begin{legal}
      \item $a$ is also on the stack.  Reassign $r$ to $c$.
      \item $a$ is not on the stack.  Spill it, then reassign $r$ to
        $c$.
      \end{legal}
    \end{legal}
  \end{legal}
\item $a = c$, but $b$ is different, or $a = b = c$. Nothing needs to
  be done.
\item $b = c$, but $a$ is different.
  \begin{legal}
  \item $a$ is dead after $I$.  Reassign $r$ to $c$.
  \item $a$ is needed far in the future.
    \begin{legal}
    \item $a$ is also assigned to a stack location.  Reassign $r$ to $c$.
    \item $a$ is not assigned to a stack location.  Spill $a$ to a
      stack location.  Then reassign $r$ to $c$.
    \end{legal}
  \item $a$ is needed soon after $I$.  Allocate a new register, say
    $t$.  Insert an instruction to copy $r$ to $t$.  Assign $t$ to
    $a$.  Reassign $r$ to $c$.
  \end{legal}
\end{legal}

\subsection{Code generation}

\subsection{Access to special variables and global functions}

To access a special variable, the code must first search the dynamic
environment in case a per-thread binding exists.  If such a binding
exists, a tagged pointer of type \texttt{cons} is returned, but the
pointer refers to an entry on the stack; a dynamic value cell.  If no
such binding exists, the global value cell is returned.

In general, for every access to a special variable, the value cell
must be searched for first.  There are many cases, however, where the
compiler can detect that multiple accesses to some special variable
must refer to the same value cell.  In that case, the (pointer to the)
value cell is a candidate for register allocation, and computing it is
loop invariant.

When it comes to the \emph{contents} of the value cell, however, the
situation is more complicated because of the possibility that multiple
threads might access the (global) value cell concurrently.  In fact,
this is a common situation when a global variable is used for
synchronization purposes.

When some function accesses a special variable multiple times, it
might seem required to read the contents of the value cell for each
such access, even though the compiler can prove that the same cell is
involved in each access.  However, this turns out not to be the case.
If none of the accesses are part of a loop and there is no externally
detectable activity between accesses (no assignment to a global
variable, no function call), then there is always a possible scenario
according to which the same value will be obtained in all the
accesses.  In such cases, not only the value cell, but also the value
itself is a candidate for register allocation.  Even if accesses are
part of a loop, in some cases the value can be cached in a register.
The necessary condition for such register allocation is that the loop
provably \emph{terminates} and that there is no externally detectable
activity between consecutive accesses.

The situation for global functions is similar to that of special
variables, except simpler since no special binding can exist for such
accesses.  While it is not very probable that anyone attempts to use
global functions for synchronization purposes, this can not be
excluded either.  An exception to the rule is when the global function
is a standard \commonlisp{} function, in which case it can not be replaced, so
it is safe to cache the function in a register.

\subsection{Access to array elements}

When an array has not been declared to be \texttt{simple} it might
seem like every access to an array element would require locking to
prevent a different thread from adjusting the array between the time
the \emph{length} is determined and the time the element is accessed.

However, in \sysname{} the rack of an array is always
\emph{internally consistent} in that the \emph{length} information
accurately reflects the number of elements.  When an array is
adjusted, a different rack is allocated, and the new
rack is put in place in a single memory store operation.
Therefore, when the elements of an array are processed in some way,
the compiler might access the rack only once and cache it
in a register.  This optimization is possible even in a loop, as long
as the compiler can prove that the loop eventually terminates, and as
long as there is no externally detectable activity between the
accesses.

\subsection{Access to slots of standard objects}

\section{Random thoughts}

The compiler should be as portable as possible.  It should use
portable Common Lisp for as many of the passes as possible.

The compiler should keep information about which registers are live,
and how values are represented in live registers, for all values of
the program counter.  This information is used by the garbage
collector to determine what registers should be scanned, and how.   It
is also used by the debugger.

%%  LocalWords:  disjunction
